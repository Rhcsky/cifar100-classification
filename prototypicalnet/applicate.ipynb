{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from configurate import get_config\n",
    "from protonets import ProtoNet\n",
    "from utils import AverageMeter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from dataloader import get_dataloader, PrototypicalBatchSampler\n",
    "from prototypical_loss import PrototypicalLoss, prototypical_evaluator, euclidean_dist\n",
    "from torch.nn import functional as F\n",
    "from easydict import EasyDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "args = EasyDict({\n",
    "    \"dataset_dir\" : 'data',\n",
    "    \"exp_name\" : 'TEST',\n",
    "    \"epochs\" : 100,\n",
    "    \"lr\" : 0.001,\n",
    "    \"lr_scheduler_step\" : 20,\n",
    "    \"lr_scheduler_gamma\" : 0.5,\n",
    "    \"manual_seed\" : 7,\n",
    "    'log_dir' : 'runs',\n",
    "    'resume' : False,\n",
    "    'iterations' : 100,\n",
    "    'classes_per_it_tr' : 50,\n",
    "    'num_support_tr' : 3,\n",
    "    'num_query_tr' : 3,\n",
    "    'classes_per_it_val' : 50,\n",
    "    'num_support_val' : 5,\n",
    "    'num_query_val' : 5,\n",
    "})\n",
    "args.log_dir = os.path.join(args.log_dir,args.exp_name)\n",
    "device = 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...Files already downloaded and verified\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_dataloader(args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "torch.cuda.cudnn_enabled = False\n",
    "np.random.seed(args.manual_seed)\n",
    "torch.manual_seed(args.manual_seed)\n",
    "torch.cuda.manual_seed(args.manual_seed)\n",
    "\n",
    "model = ProtoNet().to(device)\n",
    "\n",
    "criterion = PrototypicalLoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), args.lr)\n",
    "\n",
    "writer = SummaryWriter(args.log_dir)\n",
    "cudnn.benchmark = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "train_data = next(iter(train_loader))\n",
    "test_data = next(iter(test_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "output = model(train_data[0])\n",
    "query_sample = model(test_data[0])\n",
    "\n",
    "loss, _, prototypes = criterion(output, train_data[1], 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-33-1e609fcb213a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0macc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_hat\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0macc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0myhat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprototypical_evaluator2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprototypes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mquery_sample\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mloss2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-33-1e609fcb213a>\u001B[0m in \u001B[0;36mprototypical_evaluator2\u001B[1;34m(prototype, input, target)\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m-\u001B[0m\u001B[0mlog_p_y\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m     \u001B[0mloss2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mNLLLoss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlog_p_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m     \u001B[0macc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0my_hat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meq\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtarget\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\programs\\python\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, weight, size_average, ignore_index, reduce, reduction)\u001B[0m\n\u001B[0;32m    207\u001B[0m     def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n\u001B[0;32m    208\u001B[0m                  reduce=None, reduction: str = 'mean') -> None:\n\u001B[1;32m--> 209\u001B[1;33m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mNLLLoss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msize_average\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreduce\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    210\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mignore_index\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mignore_index\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    211\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\programs\\python\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, weight, size_average, reduce, reduction)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0m_WeightedLoss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_Loss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msize_average\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreduce\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mstr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'mean'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 25\u001B[1;33m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_WeightedLoss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msize_average\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreduce\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     26\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mregister_buffer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'weight'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\programs\\python\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, size_average, reduce, reduction)\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_Loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0msize_average\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mreduce\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreduction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_Reduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlegacy_get_string\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msize_average\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreduce\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreduction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreduction\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\programs\\python\\lib\\site-packages\\torch\\nn\\_reduction.py\u001B[0m in \u001B[0;36mlegacy_get_string\u001B[1;34m(size_average, reduce, emit_warning)\u001B[0m\n\u001B[0;32m     35\u001B[0m         \u001B[0mreduce\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 37\u001B[1;33m     \u001B[1;32mif\u001B[0m \u001B[0msize_average\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mreduce\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     38\u001B[0m         \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'mean'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mreduce\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "def prototypical_evaluator2(prototype, input, target):\n",
    "    dists = euclidean_dist(input, prototype)\n",
    "    log_p_y = F.log_softmax(-dists,dim=1)\n",
    "    y_hat = log_p_y.argmax(1)\n",
    "\n",
    "    loss = -log_p_y.squeeze().view(-1).mean()\n",
    "    loss2 = torch.nn.NLLLoss(log_p_y, target)\n",
    "    acc = y_hat.eq(target.squeeze()).float().mean()\n",
    "\n",
    "    return loss, loss2, acc, y_hat\n",
    "\n",
    "loss, loss2, acc, yhat = prototypical_evaluator2(prototypes,query_sample,test_data[1])\n",
    "\n",
    "print(loss,loss2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  2],\n",
      "        [  3],\n",
      "        [ 29],\n",
      "        [ 31],\n",
      "        [ 37],\n",
      "        [ 70],\n",
      "        [ 72],\n",
      "        [ 79],\n",
      "        [ 82],\n",
      "        [ 91],\n",
      "        [103],\n",
      "        [104],\n",
      "        [111],\n",
      "        [119],\n",
      "        [146]])\n",
      "150\n",
      "42.1596565246582 tensor(0.1000)\n"
     ]
    }
   ],
   "source": [
    "def prototypical_loss2(input, target, n_support, device):\n",
    "    '''\n",
    "    Inspired by https://github.com/jakesnell/prototypical-networks/blob/master/protonets/models/few_shot.py\n",
    "\n",
    "    Compute the barycentres by averaging the features of n_support\n",
    "    samples for each class in target, computes then the distances from each\n",
    "    samples' features to each one of the barycentres, computes the\n",
    "    log_probability for each n_query samples for each one of the current\n",
    "    classes, of appartaining to a class c, loss and accuracy are then computed\n",
    "    and returned\n",
    "    Args:\n",
    "    - input: the model output for a batch of samples\n",
    "    - target: ground truth for the above batch of samples\n",
    "    - n_support: number of samples to keep in account when computing\n",
    "      barycentres, for each one of the current classes\n",
    "    '''\n",
    "\n",
    "    classes = torch.unique(target)\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    # Make prototypes\n",
    "    support_idxs = torch.stack(list(map(lambda c: target.eq(c).nonzero()[:n_support].squeeze(1), classes)))\n",
    "    prototypes = torch.stack([input[idx_list].mean(0) for idx_list in support_idxs])\n",
    "\n",
    "    # Make query samples\n",
    "    n_query = target.eq(classes[0].item()).sum().item() - n_support\n",
    "    query_idxs = torch.stack(list(map(lambda c: target.eq(c).nonzero()[n_support:], classes))).view(-1)\n",
    "    query_samples = input[query_idxs]\n",
    "\n",
    "    dists = euclidean_dist(query_samples, prototypes)\n",
    "\n",
    "    log_p_y = F.log_softmax(-dists, dim=1)\n",
    "    y_hat = log_p_y.argmax(1)\n",
    "    target_idxs = torch.LongTensor([x for x in range(n_classes) for _ in range(n_query)]).to(device)\n",
    "\n",
    "    loss_val = torch.nn.NLLLoss()(log_p_y, target_idxs)\n",
    "    acc_val = y_hat.eq(target_idxs).float().mean()\n",
    "\n",
    "    return loss_val, acc_val\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    loss,acc = prototypical_loss2(output,train_data[1] , 3, 'cpu')\n",
    "    print(loss.item(),acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_label = torch.unique(test_data[1])\n",
    "yhat_label = torch.unique(yhat)\n",
    "yhat_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n        18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input, train_label = train_data[0], train_data[1]\n",
    "\n",
    "train_class = torch.unique(train_label)\n",
    "tc = train_class[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}